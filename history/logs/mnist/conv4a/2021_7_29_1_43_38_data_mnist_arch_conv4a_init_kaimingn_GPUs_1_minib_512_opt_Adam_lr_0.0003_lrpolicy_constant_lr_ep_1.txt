
========> The following is the setup for this run:

2021_7_29_1_43_38_data_mnist_arch_conv4a_init_kaimingn_GPUs_1_minib_512_opt_Adam_lr_0.0003_lrpolicy_constant_lr_ep_1

arch: conv4a
pretrained: False
resume: 
dataname: mnist
datapath: ./data/mnist/
workers: 20
batch_size: 512
init_policy: kaimingn
init_kaiming_mode: fan_in
init_kaiming_nonlinearity: relu
init_bias: zero
optimizer: Adam
epochs: 1
initial_epoch: 0
label_smoothing: 0.0
weight_decay: 0.0
lr: 0.0003
lr_policy: constant_lr
warmup_length: 0
lr_gamma: 0.0
lr_steps: None
lowest_lr: 0.0001
scale_coslr: 1
exp_coslr: 1
normal_exp_scale: 1500
momentum: 0.0
nesterov: False
evaluate: False
print_freq_tr: 10
print_freq_ts: 10
config: mnist_conv4a_train
logterminal: True
save_stages: False
gpu_idx: ['6']
local_rank: 0
channels_last: False
lr_step: 0
distributed: False
world_size: 1

=> Global rank of the current node is 0 and the process id is 27000.
=> There are 1 process(es) runing on GPU(s).
=> Visible GPU(s) are ['6'] for running 1 process(es).
=> Execute `nvidia-smi` on a differnt terminal to see used GPUs.
=> GPU 6 whose id is 0 is being used for training of the current process.

=> The model, i.e., conv4a, is being replicated on 1 processes.

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  10/ 118] | Time(avg): 1.39 | Speed: (pics/sec):  3679
Learning rate: 0.00030000 | Curr loss: 2.6733 | Avg loss: 3.7569 | Prec@1(avg) 12.19 % | Prec@5(avg) 50.74 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  20/ 118] | Time(avg): 0.87 | Speed: (pics/sec):  5855
Learning rate: 0.00030000 | Curr loss: 2.3452 | Avg loss: 3.1314 | Prec@1(avg) 16.88 % | Prec@5(avg) 57.38 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  30/ 118] | Time(avg): 0.69 | Speed: (pics/sec):  7370
Learning rate: 0.00030000 | Curr loss: 2.1342 | Avg loss: 2.8169 | Prec@1(avg) 19.79 % | Prec@5(avg) 61.55 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  40/ 118] | Time(avg): 0.60 | Speed: (pics/sec):  8503
Learning rate: 0.00030000 | Curr loss: 2.0022 | Avg loss: 2.6324 | Prec@1(avg) 21.78 % | Prec@5(avg) 66.32 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  50/ 118] | Time(avg): 0.55 | Speed: (pics/sec):  9368
Learning rate: 0.00030000 | Curr loss: 1.8621 | Avg loss: 2.4930 | Prec@1(avg) 24.55 % | Prec@5(avg) 70.60 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  60/ 118] | Time(avg): 0.55 | Speed: (pics/sec):  9283
Learning rate: 0.00030000 | Curr loss: 1.6619 | Avg loss: 2.3682 | Prec@1(avg) 28.64 % | Prec@5(avg) 74.38 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  70/ 118] | Time(avg): 0.53 | Speed: (pics/sec):  9714
Learning rate: 0.00030000 | Curr loss: 1.3833 | Avg loss: 2.2457 | Prec@1(avg) 32.61 % | Prec@5(avg) 77.39 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  80/ 118] | Time(avg): 0.52 | Speed: (pics/sec):  9917
Learning rate: 0.00030000 | Curr loss: 1.2268 | Avg loss: 2.1255 | Prec@1(avg) 36.57 % | Prec@5(avg) 79.70 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  90/ 118] | Time(avg): 0.50 | Speed: (pics/sec): 10163
Learning rate: 0.00030000 | Curr loss: 1.0464 | Avg loss: 2.0107 | Prec@1(avg) 40.35 % | Prec@5(avg) 81.60 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 100/ 118] | Time(avg): 0.49 | Speed: (pics/sec): 10529
Learning rate: 0.00030000 | Curr loss: 0.9341 | Avg loss: 1.9051 | Prec@1(avg) 43.71 % | Prec@5(avg) 83.18 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 110/ 118] | Time(avg): 0.47 | Speed: (pics/sec): 10873
Learning rate: 0.00030000 | Curr loss: 0.7097 | Avg loss: 1.8035 | Prec@1(avg) 46.98 % | Prec@5(avg) 84.54 %

Validation: Epoch: [ 1/ 1] | Seen data: [  10/  20] | Time(avg): 0.70 | Speed: (pics/sec):  7299
Curr loss: 0.6220 | Avg loss: 0.7175 | Prec@1(avg) 80.90 % | Prec@5(avg) 98.59 %

Validation: Epoch: [ 1/ 1] | Seen data: [  20/  20] | Time(avg): 0.46 | Speed: (pics/sec): 11181
Curr loss: 0.7410 | Avg loss: 0.6266 | Prec@1(avg) 84.45 % | Prec@5(avg) 98.96 %

