
========> The following is the setup for this run:

2021_7_29_1_41_14_data_mnist_arch_conv4a_init_kaimingn_GPUs_1_minib_512_opt_SGD+M_lr_0.032_lrpolicy_cosine_lr_ep_1

arch: conv4a
pretrained: False
resume: 
dataname: mnist
datapath: ./data/mnist/
workers: 20
batch_size: 512
init_policy: kaimingn
init_kaiming_mode: fan_in
init_kaiming_nonlinearity: relu
init_bias: zero
optimizer: SGD+M
epochs: 1
initial_epoch: 0
label_smoothing: 0.0
weight_decay: 0.0
lr: 0.032
lr_policy: cosine_lr
warmup_length: 0
lr_gamma: 0.0
lr_steps: None
lowest_lr: 0.0001
scale_coslr: 1
exp_coslr: 1
normal_exp_scale: 1500
momentum: 0.0
nesterov: False
evaluate: False
print_freq_tr: 10
print_freq_ts: 10
config: mnist_conv4a_train
logterminal: True
save_stages: False
gpu_idx: ['0']
local_rank: 0
channels_last: False
lr_step: 0
distributed: False
world_size: 1

=> Global rank of the current node is 0 and the process id is 26478.
=> There are 1 process(es) runing on GPU(s).
=> Visible GPU(s) are ['0'] for running 1 process(es).
=> Execute `nvidia-smi` on a differnt terminal to see used GPUs.
=> GPU 0 whose id is 0 is being used for training of the current process.

=> The model, i.e., conv4a, is being replicated on 1 processes.

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  10/ 118] | Time(avg): 1.42 | Speed: (pics/sec):  3617
Learning rate: 0.03200000 | Curr loss: 2.4011 | Avg loss: 4.7753 | Prec@1(avg) 10.59 % | Prec@5(avg) 51.13 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  20/ 118] | Time(avg): 0.87 | Speed: (pics/sec):  5882
Learning rate: 0.03200000 | Curr loss: 2.2833 | Avg loss: 3.5436 | Prec@1(avg) 12.80 % | Prec@5(avg) 52.63 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  30/ 118] | Time(avg): 0.71 | Speed: (pics/sec):  7163
Learning rate: 0.03200000 | Curr loss: 2.2337 | Avg loss: 3.1137 | Prec@1(avg) 16.62 % | Prec@5(avg) 55.90 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  40/ 118] | Time(avg): 0.68 | Speed: (pics/sec):  7535
Learning rate: 0.03200000 | Curr loss: 2.1640 | Avg loss: 2.8857 | Prec@1(avg) 19.56 % | Prec@5(avg) 60.94 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  50/ 118] | Time(avg): 0.61 | Speed: (pics/sec):  8333
Learning rate: 0.03200000 | Curr loss: 2.0831 | Avg loss: 2.7319 | Prec@1(avg) 22.18 % | Prec@5(avg) 65.19 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  60/ 118] | Time(avg): 0.58 | Speed: (pics/sec):  8894
Learning rate: 0.03200000 | Curr loss: 2.0577 | Avg loss: 2.6164 | Prec@1(avg) 23.23 % | Prec@5(avg) 67.60 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  70/ 118] | Time(avg): 0.54 | Speed: (pics/sec):  9494
Learning rate: 0.03200000 | Curr loss: 1.9413 | Avg loss: 2.5267 | Prec@1(avg) 24.35 % | Prec@5(avg) 68.93 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  80/ 118] | Time(avg): 0.51 | Speed: (pics/sec):  9981
Learning rate: 0.03200000 | Curr loss: 1.8719 | Avg loss: 2.4534 | Prec@1(avg) 25.43 % | Prec@5(avg) 69.97 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  90/ 118] | Time(avg): 0.49 | Speed: (pics/sec): 10347
Learning rate: 0.03200000 | Curr loss: 1.8141 | Avg loss: 2.3845 | Prec@1(avg) 26.59 % | Prec@5(avg) 71.25 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 100/ 118] | Time(avg): 0.48 | Speed: (pics/sec): 10732
Learning rate: 0.03200000 | Curr loss: 1.8779 | Avg loss: 2.3233 | Prec@1(avg) 27.83 % | Prec@5(avg) 72.66 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 110/ 118] | Time(avg): 0.48 | Speed: (pics/sec): 10745
Learning rate: 0.03200000 | Curr loss: 1.9656 | Avg loss: 2.2789 | Prec@1(avg) 28.96 % | Prec@5(avg) 73.52 %

Validation: Epoch: [ 1/ 1] | Seen data: [  10/  20] | Time(avg): 0.69 | Speed: (pics/sec):  7417
Curr loss: 1.7574 | Avg loss: 1.8465 | Prec@1(avg) 32.01 % | Prec@5(avg) 81.82 %

Validation: Epoch: [ 1/ 1] | Seen data: [  20/  20] | Time(avg): 0.46 | Speed: (pics/sec): 11244
Curr loss: 1.8862 | Avg loss: 1.8170 | Prec@1(avg) 32.19 % | Prec@5(avg) 83.94 %

