
========> The following is the setup for this run:

2021_7_29_15_23_22_data_cifar10_arch_conv4_init_kaimingn_GPUs_1_minib_60_opt_Adam_lr_0.0003_lrpolicy_constant_lr_ep_1

arch: conv4
pretrained: False
resume: 
dataname: cifar10
datapath: ./data/cifar10/
workers: 20
batch_size: 60
init_policy: kaimingn
init_kaiming_mode: fan_in
init_kaiming_nonlinearity: relu
init_bias: zero
optimizer: Adam
epochs: 1
initial_epoch: 0
label_smoothing: 0.0
weight_decay: 0.0
lr: 0.0003
lr_policy: constant_lr
warmup_length: 0
lr_gamma: 0.0
lr_steps: None
lowest_lr: 0.0001
scale_coslr: 1
exp_coslr: 1
normal_exp_scale: 1500
momentum: 0.0
nesterov: False
evaluate: False
print_freq_tr: 10
print_freq_ts: 10
config: cifar10_conv4_train
logterminal: False
save_stages: False
gpu_idx: ['0']
local_rank: 0
channels_last: False
lr_step: 0
prepruned_model: False
pruning_strategy: lottery
percent: 0
initial_stage: 0
stages: 5
local_prune: False
prune_bias: False
prune_bn: False
local_quant: False
distributed: False
world_size: 1

=> Global rank of the current node is 0 and the process id is 35739.
=> There are 1 process(es) runing on GPU(s).
=> Visible GPU(s) are ['0'] for running 1 process(es).
=> Execute `nvidia-smi` on a differnt terminal to see used GPUs.
=> GPU 0 whose id is 0 is being used for training of the current process.

Files already downloaded and verified
=> The model, i.e., conv4, is being replicated on 1 processes.

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  10/ 834] | Time(avg): 0.96 | Speed: (pics/sec):   623
Learning rate: 0.00030000 | Curr loss: 2.9387 | Avg loss: 4.2244 | Prec@1(avg) 11.50 % | Prec@5(avg) 55.00 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  20/ 834] | Time(avg): 0.70 | Speed: (pics/sec):   861
Learning rate: 0.00030000 | Curr loss: 2.2870 | Avg loss: 3.2828 | Prec@1(avg) 13.00 % | Prec@5(avg) 58.08 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  30/ 834] | Time(avg): 0.56 | Speed: (pics/sec):  1074
Learning rate: 0.00030000 | Curr loss: 2.2095 | Avg loss: 2.9191 | Prec@1(avg) 14.94 % | Prec@5(avg) 61.67 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  40/ 834] | Time(avg): 0.47 | Speed: (pics/sec):  1279
Learning rate: 0.00030000 | Curr loss: 2.0507 | Avg loss: 2.7059 | Prec@1(avg) 17.83 % | Prec@5(avg) 64.92 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  50/ 834] | Time(avg): 0.43 | Speed: (pics/sec):  1397
Learning rate: 0.00030000 | Curr loss: 1.8804 | Avg loss: 2.5617 | Prec@1(avg) 19.77 % | Prec@5(avg) 67.50 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  60/ 834] | Time(avg): 0.40 | Speed: (pics/sec):  1488
Learning rate: 0.00030000 | Curr loss: 1.9007 | Avg loss: 2.4658 | Prec@1(avg) 20.86 % | Prec@5(avg) 69.06 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  70/ 834] | Time(avg): 0.39 | Speed: (pics/sec):  1526
Learning rate: 0.00030000 | Curr loss: 1.9584 | Avg loss: 2.3876 | Prec@1(avg) 21.90 % | Prec@5(avg) 71.21 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  80/ 834] | Time(avg): 0.39 | Speed: (pics/sec):  1521
Learning rate: 0.00030000 | Curr loss: 1.8668 | Avg loss: 2.3288 | Prec@1(avg) 23.10 % | Prec@5(avg) 72.54 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [  90/ 834] | Time(avg): 0.38 | Speed: (pics/sec):  1588
Learning rate: 0.00030000 | Curr loss: 1.9502 | Avg loss: 2.2788 | Prec@1(avg) 23.96 % | Prec@5(avg) 73.80 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 100/ 834] | Time(avg): 0.38 | Speed: (pics/sec):  1578
Learning rate: 0.00030000 | Curr loss: 1.9308 | Avg loss: 2.2368 | Prec@1(avg) 24.57 % | Prec@5(avg) 74.87 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 110/ 834] | Time(avg): 0.37 | Speed: (pics/sec):  1616
Learning rate: 0.00030000 | Curr loss: 1.8358 | Avg loss: 2.2017 | Prec@1(avg) 25.00 % | Prec@5(avg) 75.68 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 120/ 834] | Time(avg): 0.38 | Speed: (pics/sec):  1559
Learning rate: 0.00030000 | Curr loss: 1.7300 | Avg loss: 2.1657 | Prec@1(avg) 26.03 % | Prec@5(avg) 76.57 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 130/ 834] | Time(avg): 0.37 | Speed: (pics/sec):  1602
Learning rate: 0.00030000 | Curr loss: 1.7829 | Avg loss: 2.1368 | Prec@1(avg) 26.62 % | Prec@5(avg) 77.23 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 140/ 834] | Time(avg): 0.36 | Speed: (pics/sec):  1645
Learning rate: 0.00030000 | Curr loss: 1.8116 | Avg loss: 2.1102 | Prec@1(avg) 27.00 % | Prec@5(avg) 77.82 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 150/ 834] | Time(avg): 0.35 | Speed: (pics/sec):  1697
Learning rate: 0.00030000 | Curr loss: 1.6618 | Avg loss: 2.0878 | Prec@1(avg) 27.49 % | Prec@5(avg) 78.30 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 160/ 834] | Time(avg): 0.35 | Speed: (pics/sec):  1730
Learning rate: 0.00030000 | Curr loss: 1.7735 | Avg loss: 2.0651 | Prec@1(avg) 28.16 % | Prec@5(avg) 78.85 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 170/ 834] | Time(avg): 0.34 | Speed: (pics/sec):  1766
Learning rate: 0.00030000 | Curr loss: 1.5733 | Avg loss: 2.0440 | Prec@1(avg) 28.60 % | Prec@5(avg) 79.35 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 180/ 834] | Time(avg): 0.33 | Speed: (pics/sec):  1796
Learning rate: 0.00030000 | Curr loss: 1.7496 | Avg loss: 2.0246 | Prec@1(avg) 29.28 % | Prec@5(avg) 79.81 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 190/ 834] | Time(avg): 0.33 | Speed: (pics/sec):  1828
Learning rate: 0.00030000 | Curr loss: 1.7143 | Avg loss: 2.0062 | Prec@1(avg) 29.79 % | Prec@5(avg) 80.24 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 200/ 834] | Time(avg): 0.33 | Speed: (pics/sec):  1800
Learning rate: 0.00030000 | Curr loss: 1.7785 | Avg loss: 1.9906 | Prec@1(avg) 30.28 % | Prec@5(avg) 80.56 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 210/ 834] | Time(avg): 0.33 | Speed: (pics/sec):  1823
Learning rate: 0.00030000 | Curr loss: 1.8835 | Avg loss: 1.9744 | Prec@1(avg) 30.70 % | Prec@5(avg) 80.90 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 220/ 834] | Time(avg): 0.32 | Speed: (pics/sec):  1856
Learning rate: 0.00030000 | Curr loss: 1.8289 | Avg loss: 1.9580 | Prec@1(avg) 31.28 % | Prec@5(avg) 81.25 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 230/ 834] | Time(avg): 0.32 | Speed: (pics/sec):  1881
Learning rate: 0.00030000 | Curr loss: 1.5781 | Avg loss: 1.9400 | Prec@1(avg) 31.80 % | Prec@5(avg) 81.63 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 240/ 834] | Time(avg): 0.32 | Speed: (pics/sec):  1894
Learning rate: 0.00030000 | Curr loss: 1.7440 | Avg loss: 1.9272 | Prec@1(avg) 32.19 % | Prec@5(avg) 81.99 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 250/ 834] | Time(avg): 0.31 | Speed: (pics/sec):  1913
Learning rate: 0.00030000 | Curr loss: 1.5947 | Avg loss: 1.9110 | Prec@1(avg) 32.71 % | Prec@5(avg) 82.33 %

Training: Num of GPUs: 1 | Epoch: [ 1/ 1] | [ 260/ 834] | Time(avg): 0.31 | Speed: (pics/sec):  1939
Learning rate: 0.00030000 | Curr loss: 1.4986 | Avg loss: 1.8980 | Prec@1(avg) 33.09 % | Prec@5(avg) 82.58 %

