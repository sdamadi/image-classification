
========> The following is the setup for this run:

2021_6_2_2_23_46_data_cifar10_arch_resnet18_init_kaimingn_GPUs_1_minib_128_opt_SGD+M_lr_0.05_lrpolicy_cosine_lr_ep_1_strategy_lottery_initstg_0_stg_160

arch: resnet18
pretrained: False
resume: 
dataname: cifar10
datapath: ./data/cifar10/
workers: 20
batch_size: 128
init_policy: kaimingn
init_kaiming_mode: fan_in
init_kaiming_nonlinearity: relu
init_bias: zero
optimizer: SGD+M
epochs: 1
label_smoothing: 0.0
weight_decay: 0.0005
lr: 0.05
lr_policy: cosine_lr
warmup_length: 0
lr_gamma: 0.0
lr_steps: None
lowest_lr: 0.001
scale_coslr: 1.06
exp_coslr: 1
normal_exp_scale: 1500
momentum: 0.9
nesterov: False
evaluate: False
initial_stage: 0
stages: 160
prepruned_model: True
quantize_prepruned: True
quantize_bias: True
prepruned_scen: 2021_5_28_1_56_44
pruning_strategy: lottery
nonpruned_percent: 3.9
mask_stage: 159
prune_bn: False
prune_bias: False
local_quant: False
asni_perc_max: 100
asni_mode: sigmoid
asni_rest_stage: 160.0
asni_sin_scale: 7
asni_sin_exponent: 2
asni_sin_mag: 20
asni_sigmoid_scale_1: 1
asni_sigmoid_trans_1: 0.5
asni_sigmoid_mag_1: 100
asni_sigmoid_scale_2: 1
asni_sigmoid_trans_2: 0.5
asni_sigmoid_mag_2: 100
percent: 0
local_prune: False
init_threshold: -10
init_threshold_type: constant
str_nonlinear: sigmoid
str_activation: relu
print_freq_tr: 10
print_freq_ts: 10
config: cifar10_resnet18_quantized
logterminal: False
save_stages: False
gpu_idx: ['6']
local_rank: 0
channels_last: False
lr_step: 0
str-nonlinear: sigmoid
str-activation: relu
distributed: False
world_size: 1

=> Global rank of the current node is 0 and the process id is 56276.
=> There are 1 process(es) runing on GPU(s).
=> Visible GPU(s) are ['6'] for running 1 process(es).
=> Execute `nvidia-smi` on a differnt terminal to see used GPUs.
=> GPU 6 whose id is 0 is being used for training of the current process.

Files already downloaded and verified
=> The model, i.e., resnet18, is being replicated on 1 processes.

