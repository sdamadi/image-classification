# python -m torch.distributed.launch --nproc_per_node=1 --master_port=$RANDOM main.py -a conv2 --dataname mnist --config mnist_conv2_train --logterminal
# ===== Configuration ===== #
config: mnist_conv2_train
# ===== Architecture ===== #
arch: 'conv2'
pretrained: False
resume: ''
# ===== Dataset ===== #
dataname: 'mnist'
datapath: './data/mnist/'
workers: 20
batch_size: 60
# ===== Initialization ===== #
init_policy: 'kaimingn'
init_kaiming_mode: 'fan_in'
init_kaiming_nonlinearity: 'relu'
init_bias: 'zero'
# ===== Optimization ======== #
optimizer: 'Adam'
epochs: 1
label_smoothing: 0.0
weight_decay: 0.0
lr: 0.0002
lr_policy: 'constant_lr'
warmup_length: 0
lr_steps: 
lr_gamma: 0.0
scale_coslr: 1
exp_coslr: 1
normal_exp_scale: 1500
momentum: 0.0
nesterov: False
evaluate: False
# ===== Pruning ======== #
prepruned_model: False
prepruned_scen: 
nonpruned_percent:
quantize_stage: 159
pruning_strategy: 'lottery'
quantize-prepruned: False
quantize-bias: True
local_quant: False
prune_bias: False
prune_bn: False
initial_stage: 0
stages: 20
# ===== Asni ======== #
asni_sin_scale: 7
asni_sin_exponent: 2
asni_sin_mag: 20
asni_perc_max: 100
asni_sigmoid_scale: 10
asni_sigmoid_trans: 0.5
asni_sigmoid_mag: 80
# ===== Lottery ======== #
percent: 0
local_prune: False
# ===== STR ======== #
init_threshold: -10
init_threshold_type: 'constant'
str-nonlinear: 'sigmoid'
str-activation: 'relu'
# ===== RigL ======== #
# ===== SNIP ======== #
# ===== Distributed processing ======== #
gpu_idx: '5'
local_rank: 0 
channels_last: False
# ===== Logging ======== #
print_freq_tr: 10
print_freq_ts: 10
logterminal: False