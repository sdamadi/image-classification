# python -m torch.distributed.launch --nproc_per_node=1 --master_port=$RANDOM main.py -a resnet34 --dataname cifar10 --gpu-idx 2 --config cifar10_resnet34_train --logterminal
# ===== Configuration ===== #
config: cifar10_resnet34_train
# ===== Architecture ===== #
arch: 'resnet34'
pretrained: False
resume: ''
# ===== Dataset ===== #
dataname: 'cifar10'
datapath: './data/cifar10/'
workers: 20
batch_size: 128
# ===== Initialization ===== #
init_policy: 'kaimingn'
init_kaiming_mode: 'fan_in'
init_kaiming_nonlinearity: 'relu'
init_bias: 'zero'
# ===== Optimization ======== #
optimizer: 'SGD+M'
epochs: 1
label_smoothing: 0.0
weight_decay: 0.0001
lr: 0.1
lr_policy: 'multistep_lr'
lr_steps: [80, 120]
lr_gamma: 0.1
warmup_length: 0
lowest_lr: 0.001
scale_coslr: 1.02
exp_coslr: 1
normal_exp_scale: 1500
momentum: 0.9
nesterov: False
evaluate: False
# ===== Distributed processing ======== #
gpu_idx: '0123'
local_rank: 0 
channels_last: False
# ===== Logging ======== #
print_freq_tr: 10
print_freq_ts: 10
logterminal: False